# -*- coding: utf-8 -*-
"""programming assignment solution.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1j-0FmNcUARlLlriI8tIs1Ijd4GCK9G5Q

#Programming Assignment : Bui Thi Thanh Mai - thi-thanh-mai.bui@tsm-education.fr

This is your home programming assignment accounting for 40% of your final grade. Copy the csv files into your “MyDrive/Classroom/UE10 Python for Finance M2 Finance FIT & FiRE 2022-2023/” folder ; access them there in your program by mounting your Google Drive.

Each student must turn in his own solution/report using this notebook by Sunday January 29 EOD ; create as many cells as you need to write your own content (but do not write inside the cells where I write these guidelines, like in here). You can get inspiration from the solution provided for Exercise 2.3 on how to exploit code and text cells to write your own report here. Scoring criteria include meeting the deadline, respecting the coding practices --cf class Introduction slides-- and quality of the written comments.

Begin by changing FIRSTNAME and LASTNAME above with your own information.

For this assignment, you will work with a restaurant dataset containing the customer ID, the time when the customer came (either for lunch or for dinner) and the cost of the first, second and third course. Every course consists of a meal and some drinks. In this case the food has a fixed cost (see the menu below) while the drinks are a random number that is added (let’s just say the restaurant has a very wide range of drinks).

The restaurant has different types of clients. The business clients are more likely to have the more expensive dishes. The restaurant is located next to a fitness center and attracts some of those healthier folks ; they usually go for soups or salads and hardly ever take desserts. Across the street there is a retirement center ; their residents usually take a three-course menu, often ending with a nice piece of pie. The other customers are one-time customers who are passing by for a quick main dish.

The end goal is to look in the data for signs of these customers. Can we find which ones are likely which type? Once we have this we can determine their likelihood of visiting, what dishes they usually order, etc. The restaurant asked us to use this data to create some simulations using this data :
*  Starters:  Soup \$3, Tomato-Mozarella \$15, Oysters \$20
*  Mains: Salad \$9, Spaghetti \$20, Steak \$25, Lobster \$40
*  Desserts: Ice cream \$15, Pie \$10

# Header
"""

# import common modules
import os
import numpy as np
import pandas as pd

# set up access to data
from google.colab import drive
mountpoint = os.path.join(os.path.abspath('.'), 'drive')
drive.mount(mountpoint, force_remount=True)
classroom = os.path.join(mountpoint, 'MyDrive/Classroom/UE10 Python for Finance M2 Finance FIT & FiRE 2022-2023/')
file1 = os.path.join(classroom, 'part1.csv')
file3 = os.path.join(classroom, 'part3.csv')

"""#Part 1 : Data Collection

In this section, I will load the data inside CSV files into dataframes using `pd.read_csv()`, understand the column types and quality of the data, and conclude on the best line of code to import the data to begin with.
"""

# first look at part1 data
table1 = pd.read_csv(file1)
table1.info()
table1.head()

"""There are 36500 entries, none of them containing null values. Each entry splits into 5 pieces of data, an identifier `CLIENT_ID`, the `TIME` of the day (either `LUNCH` or `DINNER`) when the meal happened, and the amounts paid for each course. The latter are well recognized as numerical data (`float64`) but `CLIENT_ID` and `TIME` were just loaded with the default `object` type. `TIME` looks like a category, let's validate this, so we can import it with a bette type."""

# validate that column TIME is in fact a category
table1['TIME'] = table1['TIME'].astype('category')
table1['TIME'].unique()

"""While there isn't null values, let's validate further the validity of the data, by checking that the numerical values are in the expected ranges (no outlier) e.g. from 0 to 20 for starters and regrouped around 0 (no starter), 3 (soup), 15 (mozza) and 20 (oysters)."""

# check min-max on courses
table1.describe()

# plot distributions
table1.hist(column=['FIRST_COURSE', 'SECOND_COURSE', 'THIRD_COURSE'])

"""Let's repeat the exploratory process for the second file."""

# first look at part3 data
table3 = pd.read_csv(file3)
table3.info()
table3.head()

# validate that column CLIENT_TYPE is in fact a category
table3['CLIENT_TYPE'] = table3['CLIENT_TYPE'].astype('category')
table3['CLIENT_TYPE'].unique()

"""In conclusion, data is clean, there is no need to discard entries. We will load columns `CLIENT_ID`, `CLIENT_TYPE` and `TIME` respectively as `string`, `category` and `category`. `object` type works for strings, it is in fact the legacy/original type for it, but let's use the future-proof `string` type introduced in Pandas 1.0.

# Part 2 : Data Preparation

In this section, I will load the `file1` data following conclusions from Part 1 and create 6 additional columns where the cost of food vs drinks are split. The logic for calculating the cost of food only will be implemented in a separate function for better code modularity, reuse and readability.
"""

# load data
table1 = pd.read_csv(file1, dtype={'CLIENT_ID': 'string', 'TIME': 'category'})

# define functions in separate cells/files
def food_cost(cost, menu):
  ''' Given food menu and course cost, return food cost as nearest inferior menu item '''
  food = 0
  for i in menu:
    if cost < i: break
    food = i
  return food

# create the new columns
table1['FIRST_FOOD'] = table1['FIRST_COURSE'].apply(food_cost, args=[[3, 15, 20]])
table1['SECOND_FOOD'] = table1['SECOND_COURSE'].apply(food_cost, args=[[9, 20, 25, 40]])
table1['THIRD_FOOD'] = table1['THIRD_COURSE'].apply(food_cost, args=[[10, 15]])

table1['FIRST_DRINK'] = table1['FIRST_COURSE'] - table1['FIRST_FOOD']
table1['SECOND_DRINK'] = table1['SECOND_COURSE'] - table1['SECOND_FOOD']
table1['THIRD_DRINK'] = table1['THIRD_COURSE'] - table1['THIRD_FOOD']

# display few lines for visual inspection
table1.head()

"""# Part 3 : Modeling

In this section, I will import and use the [K-Means clustering algorithm](#scrollTo=VpJhlGd857nb&line=2&uniqifier=1) from scikit-learn to learn the client type from the 3 features of food cost. Based on what we know about each client type, e.g. one-time customers go for a quick main dish only, I will then map the learned labels to the 4 categories `['Business', 'Onetime', 'Retirement', 'Healthy']`.
"""

from sklearn.cluster import KMeans

# set seed to get predictable results on labels
np.random.seed(5)

# perform k-means clustering
X = table1.loc[:,['FIRST_FOOD', 'SECOND_FOOD', 'THIRD_FOOD']]
kmeans = KMeans(n_clusters=4).fit(X)

# assign the learned labels to new column LABEL
X['LABEL'] = pd.Series(kmeans.labels_)

# id customer type based on behavior
for i in range(4):
  print(X[X['LABEL'] == i].describe())

"""We recognize the `Healthy` customers in the first cluster above ; they usually go for soups (\$3) and salads (\$9) and hardly take desserts.
We recognize the `Business` customers in the second cluster above ; they are more likely to have the more expensive dishes.
We recognize the `Onetime` customers in the third cluster above ; they go for a quick main dish.
We recognize the `Retirement` customers in the last cluster above ; they usually take a three-course menu, often ending with a nice piece of pie (\$10).
We can now replace the cluster number by the matching category for more intuitive data exploration later.
"""

# assign recognized labels
labels = {0:'Healthy', 1:'Business', 2:'Onetime', 3:'Retirement'}
X['LABEL'] = X['LABEL'].map(labels)

"""For plotting the data, I will import and use the [Plotly Express](#scrollTo=VpJhlGd857nb&line=2&uniqifier=1) library for its ease of use and interactive graphics."""

# 3d scatter plot
import plotly.express as px
fig = px.scatter_3d(X, x='FIRST_FOOD', y='SECOND_FOOD', z='THIRD_FOOD', color='LABEL')
fig.show()

"""#Part 4 : Evaluation

In this section, we will evaluate how well our model above learned the client type by calculating accuracy, i.e. the percentage of when it gets it right. The ground truth is available in `file3` that we first load following conclusions from Part 1.
"""

# load data
table3 = pd.read_csv(file3, dtype={'CLIENT_ID': 'string', 'CLIENT_TYPE': 'category'})

# no duplicate customer in table1 = no special precaution for pd.merge
np.testing.assert_equal(len(table3), table1['CLIENT_ID'].nunique())

# merge learned data and ground truth on CLIENT_ID
X['CLIENT_ID'] = table1['CLIENT_ID']
df = pd.merge(X[['CLIENT_ID', 'LABEL']], table3, on='CLIENT_ID')

# calculate accuracy
print(f"{len(df[df['LABEL']==df['CLIENT_TYPE']])/len(df):.2%}")

"""scikit-learn has a [classification report](#scrollTo=VpJhlGd857nb&line=3&uniqifier=1) for more exhaustive model evaluation. """

from sklearn.metrics import classification_report
print(classification_report(df['CLIENT_TYPE'],df['LABEL']))

"""#Part 5 : Simulation

Before answering the questions, let's bring back all columns into our working dataframe `X` and add a useful `TOTAL` column for the whole price of the meal. Also I am printing out some simple aggregates to manually validate results further down.
"""

for column in table1.columns: X[column] = table1[column]
X['TOTAL'] = X['FIRST_COURSE'] + X['SECOND_COURSE'] + X['THIRD_COURSE']

# number of clients per type
X.groupby('LABEL')['CLIENT_ID'].count()

# number of dishes per client type
# X.groupby(['LABEL','FIRST_FOOD'])['FIRST_COURSE'].count()
X.groupby(['LABEL','SECOND_FOOD'])['SECOND_COURSE'].count()
# X.groupby(['LABEL','THIRD_FOOD'])['THIRD_COURSE'].count()

"""Plot the distribution of clients."""

X['LABEL'].hist()

"""Determine the likelihood for each type of client to order a certain course."""

# group by LABEL
# calculate pct of non-zero values for each course
# pretty print as pct
X.groupby('LABEL')[['FIRST_COURSE', 'SECOND_COURSE', 'THIRD_COURSE']].agg(lambda x: len(x[x != 0]) / len(x)).applymap("{:.2%}".format)

"""Determine the probability of a certain type of customer ordering a certain dish."""

df = pd.DataFrame()

# one-hot encoding of dishes
df['STARTER'] = X['FIRST_FOOD'].map({3:'Soup', 15:'Caprese', 20:'Oysters'})
df['MAIN'] = X['SECOND_FOOD'].map({9:'Salad', 20:'Spaghetti', 25:'Steak', 40:'Lobster'})
df['DESSERT'] = X['THIRD_FOOD'].map({15:'Icecream', 10:'Pie'})
df  = pd.get_dummies(df)

# group by LABEL
# mean works as pct of non-zero values in the presence of only 0 & 1
# pretty print as pct
df['LABEL'] = X['LABEL']
df.groupby('LABEL').mean().applymap("{:.2%}".format)

"""What's the percentage of clients not ordering a drink with each of his course?"""

# counting meals with 1 food but no associated drinks
count = len(X[((X['FIRST_DRINK']  == 0) & (X['FIRST_FOOD']  > 0)) |
              ((X['SECOND_DRINK'] == 0) & (X['SECOND_FOOD'] > 0)) |
              ((X['THIRD_DRINK']  == 0) & (X['THIRD_FOOD']  > 0))])
print(f"{count/len(X):.2%}")

"""How would the revenue change if you can influence every other Healthy customer to spend/behave like a Onetime customer instead?"""

df = pd.DataFrame()

# average spent per client type
df['AVG'] = X.groupby('LABEL')['TOTAL'].mean()

# original client split
df['OLD'] = X.groupby('LABEL')['CLIENT_ID'].count()

# new client split
df['NEW'] = df['OLD']
convert = round(df.loc['Healthy','OLD'] / 2)
df.loc['Healthy','NEW'] -= convert
df.loc['Onetime','NEW'] += convert

# compare revenue before vs after
old = df['AVG'].dot(df['OLD'])
new = df['AVG'].dot(df['NEW'])
print(f"{new - old:.2f} in value, {new / old - 1:.2%} in pct")

"""By how much does revenue go up if the spaghetti dish increases by 10%?"""

# revenue generated by spaghetti
spaghetti = X[X['SECOND_FOOD'] == 20]['SECOND_FOOD'].sum()

# total revenue
total = X['TOTAL'].sum()

print(f"{spaghetti * .1:.2f} in value, {spaghetti * .1 / total:.2%} in pct")

"""# References

*   https://scikit-learn.org/stable/modules/clustering.html#k-means
*   https://plotly.com/python/plotly-express/
*   https://scikit-learn.org/stable/modules/model_evaluation.html#classification-report
"""